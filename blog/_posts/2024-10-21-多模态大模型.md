---
layout: post
title: 多模态大模型
truncated_preview: true
excerpt_separator: <!--more--> 


---

<div class="message">
    多模态大模型是一个讲录音，图片，文字结合在一起的模型，端到端的训练，可能图片采用的是clip，语音采用的是whisper，大模型这一段有各种各样的，但是万变不离其宗，但是我们想要搞懂，多模态大模型是如何训练的，是一个非常有意思的事情，包括多模态理论上是可以做什么的？或者说多模态大模型能力的边界是什么？我决定从[Qwen2vl](https://arxiv.org/pdf/2409.12191)下手，当然这是一个很好的一个example,篇幅并不是很大，并且母语为中文来写的英文论文，中国人比较看得懂（笑。其次最近也有一些其他的工作陆续推出，比如[mini-omni2](https://arxiv.org/pdf/2410.11190)，之前omini1的端到端是没有图片的识别，现在也支持了更多的模态，并且一些图片模态的也开始陆续支持声音的这一向量。
</div>    
<!--more-->
    从Qwen2-vl这边论文看来，
    ## 训练的方法

